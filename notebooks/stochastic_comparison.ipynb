{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic AlphaZero Comparison\n",
    "\n",
    "This notebook compares three approaches on the Game of Pig:\n",
    "\n",
    "1. **Standard AlphaZero** - Treats dice rolls as part of the environment (hidden stochasticity)\n",
    "2. **Stochastic AlphaZero** - Explicitly models chance nodes with expectimax in MCTS\n",
    "3. **Hold20 Baseline** - Simple heuristic: hold when turn total >= 20\n",
    "\n",
    "We train until both AlphaZero variants beat Hold20 and compare:\n",
    "- Win rate per iteration\n",
    "- Sample efficiency (win rate / total simulations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Julia (Colab only)\n",
    "\n",
    "If running on Google Colab, first install Julia by running this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colab - Install Julia\n",
    "# Uncomment and run this cell FIRST if on Colab\n",
    "\n",
    "# %%shell\n",
    "# set -e\n",
    "# curl -fsSL https://install.julialang.org | sh -s -- --yes\n",
    "# pip install -q julia\n",
    "# julia -e 'using Pkg; Pkg.add(\"IJulia\")'\n",
    "# echo \"Restart runtime after this cell completes!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 2: Install AlphaZero.jl Package\n\nRun the cell below to install dependencies and AlphaZero. This takes ~5-8 minutes the first time due to Julia compilation.\n\n**Note**: Plots.jl is now optional - AlphaZero will run without it. We install it separately for visualization."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install AlphaZero.jl (Plots is now optional - no OpenGL required!)\nusing Pkg\n\n# Install the package (this takes ~5-8 min first time for compilation)\nprintln(\"Installing AlphaZero.jl from stochastic-mcts branch...\")\nprintln(\"This may take several minutes for compilation...\")\nPkg.add(url=\"https://github.com/sile16/AlphaZero.jl\", rev=\"stochastic-mcts\")\n\n# Install Plots for visualization (optional but recommended)\nprintln(\"Installing Plots for visualization...\")\nENV[\"GKSwstype\"] = \"100\"  # Headless mode for Colab\nPkg.add(\"Plots\")\n\nprintln(\"Installation complete!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "println(\"Loading AlphaZero...\")\n",
    "using AlphaZero\n",
    "using AlphaZero.Examples: Pig\n",
    "using Random\n",
    "using Statistics\n",
    "using Printf\n",
    "\n",
    "println(\"Loading Plots...\")\n",
    "using Plots\n",
    "gr()  # Use GR backend (works in notebooks)\n",
    "\n",
    "println(\"All packages loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Deterministic Pig Game\n",
    "\n",
    "This version hides the dice roll inside `play!` - standard AlphaZero won't know about the stochastic nature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module DeterministicPig\n",
    "\n",
    "import AlphaZero.GI\n",
    "using Random\n",
    "\n",
    "const TARGET_SCORE = 100\n",
    "const ROLL = 1\n",
    "const HOLD = 2\n",
    "\n",
    "const Player = Bool\n",
    "const WHITE = true\n",
    "const BLACK = false\n",
    "\n",
    "# State without awaiting_dice - dice is rolled immediately\n",
    "const State = @NamedTuple{\n",
    "    p1_score::Int,\n",
    "    p2_score::Int,\n",
    "    turn_total::Int,\n",
    "    curplayer::Player\n",
    "}\n",
    "\n",
    "const INITIAL_STATE = State((0, 0, 0, WHITE))\n",
    "\n",
    "struct GameSpec <: GI.AbstractGameSpec end\n",
    "\n",
    "GI.two_players(::GameSpec) = true\n",
    "GI.actions(::GameSpec) = [ROLL, HOLD]\n",
    "\n",
    "# NO chance outcomes - this is \"deterministic\" from MCTS perspective\n",
    "GI.num_chance_outcomes(::GameSpec) = 0\n",
    "\n",
    "function GI.vectorize_state(::GameSpec, state)\n",
    "    p1_norm = Float32(state.p1_score / TARGET_SCORE)\n",
    "    p2_norm = Float32(state.p2_score / TARGET_SCORE)\n",
    "    turn_norm = Float32(state.turn_total / TARGET_SCORE)\n",
    "    curplayer = state.curplayer == WHITE ? 1f0 : 0f0\n",
    "    return Float32[p1_norm, p2_norm, turn_norm, curplayer]\n",
    "end\n",
    "\n",
    "mutable struct GameEnv <: GI.AbstractGameEnv\n",
    "    state::State\n",
    "    rng::AbstractRNG\n",
    "end\n",
    "\n",
    "GI.spec(::GameEnv) = GameSpec()\n",
    "GI.current_state(g::GameEnv) = g.state\n",
    "GI.set_state!(g::GameEnv, s) = (g.state = s)\n",
    "GI.white_playing(g::GameEnv) = g.state.curplayer == WHITE\n",
    "\n",
    "function GI.init(::GameSpec)\n",
    "    return GameEnv(INITIAL_STATE, Random.default_rng())\n",
    "end\n",
    "\n",
    "function GI.init(::GameSpec, state)\n",
    "    return GameEnv(state, Random.default_rng())\n",
    "end\n",
    "\n",
    "function GI.game_terminated(g::GameEnv)\n",
    "    return g.state.p1_score >= TARGET_SCORE || g.state.p2_score >= TARGET_SCORE\n",
    "end\n",
    "\n",
    "function GI.white_reward(g::GameEnv)\n",
    "    if g.state.p1_score >= TARGET_SCORE\n",
    "        return 1.0\n",
    "    elseif g.state.p2_score >= TARGET_SCORE\n",
    "        return -1.0\n",
    "    else\n",
    "        return 0.0\n",
    "    end\n",
    "end\n",
    "\n",
    "# NOT a chance node - stochasticity is hidden\n",
    "GI.is_chance_node(g::GameEnv) = false\n",
    "\n",
    "function GI.actions_mask(g::GameEnv)\n",
    "    return [true, true]  # Both actions always available\n",
    "end\n",
    "\n",
    "function GI.play!(g::GameEnv, action)\n",
    "    s = g.state\n",
    "    \n",
    "    if action == ROLL\n",
    "        # Dice roll happens INSIDE play! - hidden from MCTS\n",
    "        die_face = rand(g.rng, 1:6)\n",
    "        \n",
    "        if die_face == 1\n",
    "            # Bust - lose turn total, switch players\n",
    "            g.state = State((s.p1_score, s.p2_score, 0, !s.curplayer))\n",
    "        else\n",
    "            # Add to turn total\n",
    "            g.state = State((s.p1_score, s.p2_score, s.turn_total + die_face, s.curplayer))\n",
    "        end\n",
    "    elseif action == HOLD\n",
    "        # Add turn total to score, switch players\n",
    "        if s.curplayer == WHITE\n",
    "            g.state = State((s.p1_score + s.turn_total, s.p2_score, 0, BLACK))\n",
    "        else\n",
    "            g.state = State((s.p1_score, s.p2_score + s.turn_total, 0, WHITE))\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "function GI.heuristic_value(g::GameEnv)\n",
    "    s = g.state\n",
    "    if s.curplayer == WHITE\n",
    "        return (s.p1_score - s.p2_score + s.turn_total) / TARGET_SCORE\n",
    "    else\n",
    "        return (s.p2_score - s.p1_score + s.turn_total) / TARGET_SCORE\n",
    "    end\n",
    "end\n",
    "\n",
    "end # module DeterministicPig\n",
    "\n",
    "println(\"DeterministicPig module defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hold20 Player (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hold20 player for both game versions\n",
    "struct Hold20Player <: AbstractPlayer\n",
    "    threshold::Int\n",
    "end\n",
    "\n",
    "Hold20Player() = Hold20Player(20)\n",
    "\n",
    "function AlphaZero.think(p::Hold20Player, game)\n",
    "    s = GI.current_state(game)\n",
    "    turn_total = hasproperty(s, :turn_total) ? s.turn_total : s[3]\n",
    "    \n",
    "    if turn_total >= p.threshold\n",
    "        π = [0.0, 1.0]  # Hold\n",
    "    else\n",
    "        π = [1.0, 0.0]  # Roll\n",
    "    end\n",
    "    return [1, 2], π\n",
    "end\n",
    "\n",
    "AlphaZero.reset!(::Hold20Player) = nothing\n",
    "\n",
    "println(\"Hold20Player defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function evaluate_vs_hold20(gspec, player, num_games=100)\n",
    "    \"\"\"Evaluate a player against Hold20, returns win rate.\"\"\"\n",
    "    hold20 = Hold20Player()\n",
    "    wins = 0\n",
    "    \n",
    "    for i in 1:num_games\n",
    "        # Alternate who plays white\n",
    "        if i % 2 == 1\n",
    "            trace = play_game(gspec, TwoPlayers(player, hold20))\n",
    "            final_game = GI.init(gspec, trace.states[end])\n",
    "            if GI.white_reward(final_game) > 0\n",
    "                wins += 1\n",
    "            end\n",
    "        else\n",
    "            trace = play_game(gspec, TwoPlayers(hold20, player))\n",
    "            final_game = GI.init(gspec, trace.states[end])\n",
    "            if GI.white_reward(final_game) < 0\n",
    "                wins += 1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return wins / num_games\n",
    "end\n",
    "\n",
    "println(\"Evaluation function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Light parameters for faster training (adjust for your compute)\n",
    "const MCTS_ITERS = 50          # MCTS iterations per move\n",
    "const SELF_PLAY_GAMES = 50     # Games per iteration\n",
    "const EVAL_GAMES = 50          # Games for evaluation\n",
    "const MAX_ITERS = 20           # Max training iterations\n",
    "const WIN_THRESHOLD = 0.55     # Win rate to consider \"beating\" Hold20\n",
    "\n",
    "# Network parameters\n",
    "const NET_WIDTH = 64\n",
    "const NET_DEPTH = 4\n",
    "\n",
    "println(\"Configuration:\")\n",
    "println(\"  MCTS iterations/turn: $MCTS_ITERS\")\n",
    "println(\"  Self-play games/iter: $SELF_PLAY_GAMES\")\n",
    "println(\"  Eval games: $EVAL_GAMES\")\n",
    "println(\"  Max iterations: $MAX_ITERS\")\n",
    "println(\"  Win threshold: $(WIN_THRESHOLD*100)%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_and_evaluate(gspec, name; max_iters=MAX_ITERS, use_gpu=false)\n",
    "    \"\"\"Train AlphaZero and evaluate against Hold20 each iteration.\"\"\"\n",
    "    \n",
    "    println(\"\\n\" * \"=\"^60)\n",
    "    println(\"Training: $name\")\n",
    "    println(\"=\"^60)\n",
    "    \n",
    "    # Results storage\n",
    "    results = Dict(\n",
    "        :win_rates => Float64[],\n",
    "        :total_sims => Int[],\n",
    "        :iterations => Int[]\n",
    "    )\n",
    "    \n",
    "    # Create network (CPU only for compatibility)\n",
    "    netparams = NetLib.SimpleNetHP(\n",
    "        width=NET_WIDTH,\n",
    "        depth_common=NET_DEPTH,\n",
    "        use_batch_norm=true,\n",
    "        batch_norm_momentum=1.0\n",
    "    )\n",
    "    nn = NetLib.SimpleNet(gspec, netparams)\n",
    "    \n",
    "    total_simulations = 0\n",
    "    \n",
    "    for iter in 1:max_iters\n",
    "        println(\"\\nIteration $iter/$max_iters\")\n",
    "        flush(stdout)\n",
    "        \n",
    "        # Self-play\n",
    "        print(\"  Self-play ($SELF_PLAY_GAMES games)... \")\n",
    "        flush(stdout)\n",
    "        mcts_env = MCTS.Env(gspec, nn, cpuct=1.0, noise_ϵ=0.25, noise_α=1.0)\n",
    "        player = MctsPlayer(mcts_env, niters=MCTS_ITERS, τ=ConstSchedule(1.0))\n",
    "        \n",
    "        for g in 1:SELF_PLAY_GAMES\n",
    "            trace = play_game(gspec, TwoPlayers(player, player))\n",
    "            total_simulations += length(trace) * MCTS_ITERS\n",
    "        end\n",
    "        println(\"done\")\n",
    "        flush(stdout)\n",
    "        \n",
    "        # Evaluation\n",
    "        print(\"  Evaluating vs Hold20 ($EVAL_GAMES games)... \")\n",
    "        flush(stdout)\n",
    "        eval_player = MctsPlayer(mcts_env, niters=MCTS_ITERS, τ=ConstSchedule(0.2))\n",
    "        win_rate = evaluate_vs_hold20(gspec, eval_player, EVAL_GAMES)\n",
    "        println(@sprintf(\"%.1f%% win rate\", win_rate * 100))\n",
    "        flush(stdout)\n",
    "        \n",
    "        # Record results\n",
    "        push!(results[:win_rates], win_rate)\n",
    "        push!(results[:total_sims], total_simulations)\n",
    "        push!(results[:iterations], iter)\n",
    "        \n",
    "        # Check if we beat Hold20\n",
    "        if win_rate >= WIN_THRESHOLD\n",
    "            println(\"\\n✓ Beat Hold20 at iteration $iter!\")\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return results\n",
    "end\n",
    "\n",
    "println(\"Training function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Standard AlphaZero (hidden stochasticity)\n",
    "println(\"Training Standard AlphaZero (deterministic MCTS)...\")\n",
    "det_gspec = DeterministicPig.GameSpec()\n",
    "results_standard = train_and_evaluate(det_gspec, \"Standard AlphaZero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Stochastic AlphaZero (explicit chance nodes)\n",
    "println(\"Training Stochastic AlphaZero (expectimax MCTS)...\")\n",
    "stoch_gspec = Pig.GameSpec()\n",
    "results_stochastic = train_and_evaluate(stoch_gspec, \"Stochastic AlphaZero\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Win Rate vs Iteration\n",
    "p1 = plot(\n",
    "    title=\"Win Rate vs Hold20 by Iteration\",\n",
    "    xlabel=\"Training Iteration\",\n",
    "    ylabel=\"Win Rate (%)\",\n",
    "    legend=:bottomright,\n",
    "    ylims=(0, 100)\n",
    ")\n",
    "\n",
    "plot!(p1, results_standard[:iterations], results_standard[:win_rates] .* 100,\n",
    "    label=\"Standard AlphaZero\", marker=:circle, linewidth=2)\n",
    "plot!(p1, results_stochastic[:iterations], results_stochastic[:win_rates] .* 100,\n",
    "    label=\"Stochastic AlphaZero\", marker=:square, linewidth=2)\n",
    "hline!(p1, [50], label=\"Break-even\", linestyle=:dash, color=:gray)\n",
    "hline!(p1, [WIN_THRESHOLD * 100], label=\"Win threshold\", linestyle=:dot, color=:green)\n",
    "\n",
    "display(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: Win Rate vs Total Simulations (Sample Efficiency)\n",
    "p2 = plot(\n",
    "    title=\"Sample Efficiency: Win Rate vs Total MCTS Simulations\",\n",
    "    xlabel=\"Total MCTS Simulations\",\n",
    "    ylabel=\"Win Rate (%)\",\n",
    "    legend=:bottomright,\n",
    "    ylims=(0, 100)\n",
    ")\n",
    "\n",
    "plot!(p2, results_standard[:total_sims], results_standard[:win_rates] .* 100,\n",
    "    label=\"Standard AlphaZero\", marker=:circle, linewidth=2)\n",
    "plot!(p2, results_stochastic[:total_sims], results_stochastic[:win_rates] .* 100,\n",
    "    label=\"Stochastic AlphaZero\", marker=:square, linewidth=2)\n",
    "hline!(p2, [50], label=\"Break-even\", linestyle=:dash, color=:gray)\n",
    "\n",
    "display(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 3: Efficiency metric (win_rate / simulations)\n",
    "p3 = plot(\n",
    "    title=\"Learning Efficiency Over Training\",\n",
    "    xlabel=\"Training Iteration\",\n",
    "    ylabel=\"Win Rate / Million Simulations\",\n",
    "    legend=:topright\n",
    ")\n",
    "\n",
    "efficiency_std = results_standard[:win_rates] ./ (results_standard[:total_sims] ./ 1e6)\n",
    "efficiency_stoch = results_stochastic[:win_rates] ./ (results_stochastic[:total_sims] ./ 1e6)\n",
    "\n",
    "plot!(p3, results_standard[:iterations], efficiency_std,\n",
    "    label=\"Standard AlphaZero\", marker=:circle, linewidth=2)\n",
    "plot!(p3, results_stochastic[:iterations], efficiency_stoch,\n",
    "    label=\"Stochastic AlphaZero\", marker=:square, linewidth=2)\n",
    "\n",
    "display(p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined plot\n",
    "combined = plot(p1, p2, p3, layout=(1, 3), size=(1400, 400))\n",
    "savefig(combined, \"stochastic_comparison_results.png\")\n",
    "println(\"Plot saved to: stochastic_comparison_results.png\")\n",
    "display(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"\\n\" * \"=\"^60)\n",
    "println(\"SUMMARY\")\n",
    "println(\"=\"^60)\n",
    "\n",
    "println(\"\\nStandard AlphaZero (hidden stochasticity):\")\n",
    "println(\"  Final win rate: $(round(results_standard[:win_rates][end] * 100, digits=1))%\")\n",
    "println(\"  Total simulations: $(results_standard[:total_sims][end])\")\n",
    "println(\"  Iterations trained: $(length(results_standard[:iterations]))\")\n",
    "\n",
    "println(\"\\nStochastic AlphaZero (explicit chance nodes):\")\n",
    "println(\"  Final win rate: $(round(results_stochastic[:win_rates][end] * 100, digits=1))%\")\n",
    "println(\"  Total simulations: $(results_stochastic[:total_sims][end])\")\n",
    "println(\"  Iterations trained: $(length(results_stochastic[:iterations]))\")\n",
    "\n",
    "# Determine winner\n",
    "std_beat = findfirst(x -> x >= WIN_THRESHOLD, results_standard[:win_rates])\n",
    "stoch_beat = findfirst(x -> x >= WIN_THRESHOLD, results_stochastic[:win_rates])\n",
    "\n",
    "println(\"\\nIterations to beat Hold20 ($(WIN_THRESHOLD*100)% threshold):\")\n",
    "if std_beat !== nothing\n",
    "    println(\"  Standard: Iteration $std_beat ($(results_standard[:total_sims][std_beat]) sims)\")\n",
    "else\n",
    "    println(\"  Standard: Did not beat Hold20\")\n",
    "end\n",
    "if stoch_beat !== nothing\n",
    "    println(\"  Stochastic: Iteration $stoch_beat ($(results_stochastic[:total_sims][stoch_beat]) sims)\")\n",
    "else\n",
    "    println(\"  Stochastic: Did not beat Hold20\")\n",
    "end\n",
    "\n",
    "# Efficiency comparison\n",
    "println(\"\\nEfficiency (final win_rate / million sims):\")\n",
    "eff_std = results_standard[:win_rates][end] / (results_standard[:total_sims][end] / 1e6)\n",
    "eff_stoch = results_stochastic[:win_rates][end] / (results_stochastic[:total_sims][end] / 1e6)\n",
    "println(\"  Standard: $(round(eff_std, digits=4))\")\n",
    "println(\"  Stochastic: $(round(eff_stoch, digits=4))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Results\n",
    "\n",
    "Based on theory, **Stochastic AlphaZero should outperform Standard AlphaZero** on Pig because:\n",
    "\n",
    "1. **Better value estimates**: Expectimax computes the true expected value over dice outcomes\n",
    "2. **Correct exploration**: MCTS explores all dice possibilities, not random samples\n",
    "3. **Training signal**: The network learns values that account for stochasticity\n",
    "\n",
    "Standard AlphaZero treats dice rolls as hidden environment dynamics, leading to:\n",
    "- Noisy value estimates (same state can lead to different outcomes)\n",
    "- Suboptimal exploration (doesn't know which outcomes are possible)\n",
    "- Confused training signal (high variance in observed rewards)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}